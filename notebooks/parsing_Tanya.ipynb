{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import langid\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "# load default skills data base\n",
    "from skillNer.general_params import SKILL_DB\n",
    "# import skill extractor\n",
    "from skillNer.skill_extractor_class import SkillExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_from_html(s: str) -> str:\n",
    "    '''\n",
    "    This functions returns a string clean from html symbols.\n",
    "    '''\n",
    "    bs_result = BeautifulSoup(s, 'lxml').text\n",
    "    result = re.sub('\\n', ' ', bs_result)\n",
    "    return result\n",
    "\n",
    "def read_csv_to_list(file_name: str) -> List[str]:\n",
    "    '''\n",
    "    This functions returns a string cleaned from html symbols.\n",
    "    '''\n",
    "    my_file = open(file_name, \"r\") \n",
    "    data = my_file.read() \n",
    "    data_list = data.split('\\n')\n",
    "    my_file.close()\n",
    "    return data_list\n",
    "\n",
    "def if_en(s: str) -> bool:\n",
    "    '''\n",
    "    This functions returns boolean whether the main langugage of text is English or not\n",
    "    '''\n",
    "    return langid.classify(str(s))[0] == 'en'\n",
    "\n",
    "def extract_languages(s: str, language_list: List[str]) -> List[str]:\n",
    "    '''\n",
    "    This functions returns list of languages that were mentioned in text\n",
    "    in case of full resmblnce with one of the languages from a given list\n",
    "    (case insensitive).\n",
    "    '''\n",
    "    lang_set = set(language.lower() for language in language_list)\n",
    "    languages = set()\n",
    "    for word in s.split():\n",
    "        if word.lower() in lang_set:\n",
    "            languages.add(word.capitalize())\n",
    "    return list(languages)\n",
    "\n",
    "def extract_skills (s: str, language_list: List) -> tuple:\n",
    "    '''\n",
    "    This function analyses bulk of text and returns lists of hard skills,\n",
    "    soft skills and languages metntioned. Hard and soft skills (soft skills \n",
    "    excluding human languages)\n",
    "    '''\n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    # init skill extractor\n",
    "    skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
    "    annotations = skill_extractor.annotate(s)\n",
    "    soft_skills = set()\n",
    "    hard_skills = set()\n",
    "    matches = annotations['results']['full_matches']+annotations['results']['ngram_scored']\n",
    "    for di in matches:\n",
    "        skill_id = di['skill_id']\n",
    "        skill_type = skill_extractor.skills_db[skill_id]['skill_type']\n",
    "        skill_name = skill_extractor.skills_db[skill_id]['skill_name']\n",
    "        if skill_type == 'Hard Skill':\n",
    "            hard_skills.add(skill_name)\n",
    "        if skill_type == 'Soft Skill' and not skill_name.count('Language'):\n",
    "            soft_skills.add(skill_name)\n",
    "    return (', '.join(list(soft_skills)), ', '.join(list(hard_skills)), ', '.join(extract_languages(s, language_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the files\n",
    "with open('job_parsing.yaml') as f:\n",
    "    conf_dict = yaml.safe_load(f)\n",
    "language_list = read_csv_to_list (conf_dict['LANGUAGE_PATH'])\n",
    "df = pd.read_csv(conf_dict['TABLE_PATH'], usecols = conf_dict['COLS'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols =df.shape[1]\n",
    "df['header.jobTitle'] = df['header.jobTitle'].map(lambda x: x.lower())\n",
    "df.insert(n_cols, 'IT_job', df['header.jobTitle'].str.contains('|'.join(conf_dict['TECH_KEYWORDS'])))\n",
    "df.insert(n_cols, 'entry_job', ~df['header.jobTitle'].str.contains('|'.join(conf_dict['SENIOR_KEYWORDS'])))\n",
    "df.insert(n_cols, 'Swiss_based', df[\"map.country\"].map(lambda x: x in conf_dict['SWISS_LOCATION']))\n",
    "\n",
    "df_Swiss_IT  = df.loc[(df['Swiss_based'] ==True) & (df['IT_job'] == True) & (df['entry_job'] == True)]\n",
    "df_Swiss_IT.insert(n_cols, 'job_description', df_Swiss_IT['job.description'].map(lambda x: clean_from_html(str(x))))\n",
    "df_Swiss_IT.insert(n_cols, 'english', df_Swiss_IT[\"job_description\"].map(lambda x: if_en(str(x))))\n",
    "df_Swiss_IT_en = df_Swiss_IT.loc[df_Swiss_IT['english'] ==True]\n",
    "df_Swiss_IT_en.drop(columns=['english', 'job.description', 'IT_job', 'Swiss_based', 'entry_job'], inplace = True)\n",
    "df_Swiss_IT_en.reset_index(drop = True, inplace = True)\n",
    "df_Swiss_IT_en['skills'] = df_Swiss_IT_en[\"job_description\"].map(lambda x: extract_skills(str(x), language_list))\n",
    "df_Swiss_IT_en['soft_skills'] = df_Swiss_IT_en['skills'].map(lambda x: x[0])\n",
    "df_Swiss_IT_en['hard_skills'] = df_Swiss_IT_en['skills'].map(lambda x: x[1])\n",
    "df_Swiss_IT_en['languages'] = df_Swiss_IT_en['skills'].map(lambda x: x[2])\n",
    "\n",
    "df_Swiss_IT_en.rename(mapper = conf_dict['COLS'], axis = 1, inplace = True)\n",
    "df_Swiss_IT_en.drop(columns = ['skills'], inplace = True)\n",
    "df_Swiss_IT_en.to_csv('IT_entry_swiss_jobs.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import csv\n",
    "fields = ['langugages']\n",
    "with open('languages.csv', 'w') as f:\n",
    "     \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "    for item in data_into_list:\n",
    "        write.writerow([item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
